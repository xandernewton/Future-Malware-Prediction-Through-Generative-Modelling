import torch
from implementations.dcgan.models import Generator, Discriminator
import random
import matplotlib.pyplot as plt
import argparse
import string
from torchvision.utils import save_image
from torch.autograd import Variable
import numpy as np
Tensor = torch.FloatTensor


def sample(path, save_path, num_samples):

    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
    print(f"Device is {device}")

    parser = argparse.ArgumentParser(description='Sampling GAN')
    
    parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")
    parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")
    parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
    parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")
    parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")
    parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")
    parser.add_argument("--latent_dim", type=int, default=128, help="dimensionality of the latent space")
    parser.add_argument("--img_size", type=int, default=64, help="size of each image dimension")
    parser.add_argument("--channels", type=int, default=3, help="number of image channels")
    parser.add_argument("--sample_interval", type=int, default=400, help="interval between image sampling")
    parser.add_argument('--path', '-p', help='path to the GAN checkpoint')
    parser.add_argument('--save_path', '-s', help='path to save the images')
 

    opt = parser.parse_args()

    state_dict = torch.load(path, map_location=device)
    print(f"path is {path}")
    print(f"GAN Epoch: {state_dict['epoch']}")
    g_state_dict = state_dict['generator_state_dict']
    d_state_dict = state_dict['discriminator_state_dict']
    # Initialize generator and discriminator
    generator = Generator(opt.latent_dim, opt.channels, opt.img_size)
    discriminator = Discriminator(opt.channels, opt.img_size)
    generator.load_state_dict(g_state_dict)
    discriminator.load_state_dict(d_state_dict)

    generator = generator.to(device)
    discriminator = discriminator.to(device)

    if num_samples > 100:
        for x in range(int(num_samples/100)+1):

            # Sample noise as generator input
            z = torch.randn(100, opt.latent_dim).to(device)
            #z = Variable(Tensor(np.random.normal(0, 1, (num_samples, opt.latent_dim))))
            # Generate a batch of images
            gen_imgs = generator(z)
            for image in gen_imgs:
                random_name = ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(10))
                #plt.imshow(image.cpu().data.permute(1, 2, 0) )
                #plt.savefig(save_path + random_name + ".png")
                save_image(image.data, f"{save_path}{random_name}.png", normalize=True)
            del z 

    


if __name__ == "__main__":
    
    parser = argparse.ArgumentParser(description='Sampling GAN')
    parser.add_argument('--path', '-p',
                        help='path to the GAN checkpoint')
    
    parser.add_argument('--save_path', '-s',
                        help='path to save the images')
    
    args = parser.parse_args()
    sample(args.path, args.save_path, 9000)